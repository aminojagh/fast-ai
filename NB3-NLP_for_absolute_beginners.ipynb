{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminojagh/fast-ai/blob/main/NB3-NLP_for_absolute_beginners.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ece9e8d9",
      "metadata": {
        "papermill": {
          "duration": 0.102825,
          "end_time": "2022-05-16T23:18:18.905047",
          "exception": false,
          "start_time": "2022-05-16T23:18:18.802222",
          "status": "completed"
        },
        "tags": [],
        "id": "ece9e8d9"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0407b5a9",
      "metadata": {
        "papermill": {
          "duration": 0.098538,
          "end_time": "2022-05-16T23:18:19.107274",
          "exception": false,
          "start_time": "2022-05-16T23:18:19.008736",
          "status": "completed"
        },
        "tags": [],
        "id": "0407b5a9"
      },
      "source": [
        "Classification models can be used to solve problems that are not, at first, obviously appropriate.\n",
        "\n",
        "For instance, consider the Kaggle [U.S. Patent Phrase to Phrase Matching](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/) competition. In this, we are tasked with comparing two words or short phrases, and scoring them based on whether they're similar or not, based on which patent class they were used in. With a score of `1` it is considered that the two inputs have identical meaning, and `0` means they have totally different meaning. For instance, *abatement* and *eliminating process* have a score of `0.5`, meaning they're somewhat similar, but not identical.\n",
        "\n",
        "It turns out that this can be represented as a classification problem. How? By representing the question like this:\n",
        "\n",
        "> For the following text...: \"TEXT1: abatement; TEXT2: eliminating process\" ...chose a category of meaning similarity: \"Different; Similar; Identical\".\n",
        "\n",
        "In this notebook we'll see how to solve the Patent Phrase Matching problem by treating it as a classification task, by representing it in a very similar way to that shown above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d21aca",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:22.653940Z",
          "iopub.status.busy": "2022-05-16T23:18:22.653136Z",
          "iopub.status.idle": "2022-05-16T23:18:31.317348Z",
          "shell.execute_reply": "2022-05-16T23:18:31.316520Z",
          "shell.execute_reply.started": "2022-04-19T22:50:15.653623Z"
        },
        "papermill": {
          "duration": 8.767461,
          "end_time": "2022-05-16T23:18:31.317539",
          "exception": false,
          "start_time": "2022-05-16T23:18:22.550078",
          "status": "completed"
        },
        "tags": [],
        "id": "e7d21aca"
      },
      "outputs": [],
      "source": [
        "!pip install datasets -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import pandas as pd, numpy as np\n",
        "from datasets import Dataset,DatasetDict\n",
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
        "from transformers import TrainingArguments,Trainer"
      ],
      "metadata": {
        "id": "xKMDpL2rnObB"
      },
      "id": "xKMDpL2rnObB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9240dd6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:21.669472Z",
          "iopub.status.busy": "2022-05-16T23:18:21.668423Z",
          "iopub.status.idle": "2022-05-16T23:18:21.671180Z",
          "shell.execute_reply": "2022-05-16T23:18:21.670701Z",
          "shell.execute_reply.started": "2022-04-19T22:50:15.636168Z"
        },
        "papermill": {
          "duration": 0.104227,
          "end_time": "2022-05-16T23:18:21.671310",
          "exception": false,
          "start_time": "2022-05-16T23:18:21.567083",
          "status": "completed"
        },
        "tags": [],
        "id": "f9240dd6"
      },
      "outputs": [],
      "source": [
        "path = Path('us-patent-phrase-to-phrase-matching')\n",
        "path.mkdir()\n",
        "# then log in to the kaggle account and download and save data in path directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd6e692",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:31.900273Z",
          "iopub.status.busy": "2022-05-16T23:18:31.899522Z",
          "iopub.status.idle": "2022-05-16T23:18:32.550557Z",
          "shell.execute_reply": "2022-05-16T23:18:32.550032Z",
          "shell.execute_reply.started": "2022-04-19T22:50:24.320172Z"
        },
        "papermill": {
          "duration": 0.789889,
          "end_time": "2022-05-16T23:18:32.550692",
          "exception": false,
          "start_time": "2022-05-16T23:18:31.760803",
          "status": "completed"
        },
        "tags": [],
        "id": "abd6e692"
      },
      "outputs": [],
      "source": [
        "!ls {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04d27700",
      "metadata": {
        "papermill": {
          "duration": 0.096057,
          "end_time": "2022-05-16T23:18:22.452686",
          "exception": false,
          "start_time": "2022-05-16T23:18:22.356629",
          "status": "completed"
        },
        "tags": [],
        "id": "04d27700"
      },
      "source": [
        "## Import and EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "410bf8a8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:33.257861Z",
          "iopub.status.busy": "2022-05-16T23:18:33.257213Z",
          "iopub.status.idle": "2022-05-16T23:18:33.338741Z",
          "shell.execute_reply": "2022-05-16T23:18:33.338223Z",
          "shell.execute_reply.started": "2022-04-19T22:50:25.036197Z"
        },
        "papermill": {
          "duration": 0.173142,
          "end_time": "2022-05-16T23:18:33.338883",
          "exception": false,
          "start_time": "2022-05-16T23:18:33.165741",
          "status": "completed"
        },
        "tags": [],
        "id": "410bf8a8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path/'train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21982274",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:34.098355Z",
          "iopub.status.busy": "2022-05-16T23:18:34.097454Z",
          "iopub.status.idle": "2022-05-16T23:18:34.145806Z",
          "shell.execute_reply": "2022-05-16T23:18:34.146201Z",
          "shell.execute_reply.started": "2022-04-19T22:50:25.149735Z"
        },
        "papermill": {
          "duration": 0.16831,
          "end_time": "2022-05-16T23:18:34.146345",
          "exception": false,
          "start_time": "2022-05-16T23:18:33.978035",
          "status": "completed"
        },
        "tags": [],
        "id": "21982274"
      },
      "outputs": [],
      "source": [
        "df.describe(include='object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d950dfad",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:34.525187Z",
          "iopub.status.busy": "2022-05-16T23:18:34.509818Z",
          "iopub.status.idle": "2022-05-16T23:18:34.535058Z",
          "shell.execute_reply": "2022-05-16T23:18:34.534144Z",
          "shell.execute_reply.started": "2022-04-19T22:50:25.226549Z"
        },
        "papermill": {
          "duration": 0.123242,
          "end_time": "2022-05-16T23:18:34.535176",
          "exception": false,
          "start_time": "2022-05-16T23:18:34.411934",
          "status": "completed"
        },
        "tags": [],
        "id": "d950dfad"
      },
      "outputs": [],
      "source": [
        "df['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "528ae2cf",
      "metadata": {
        "papermill": {
          "duration": 0.090197,
          "end_time": "2022-05-16T23:18:35.078246",
          "exception": false,
          "start_time": "2022-05-16T23:18:34.988049",
          "status": "completed"
        },
        "tags": [],
        "id": "528ae2cf"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff7d7a2a",
      "metadata": {
        "papermill": {
          "duration": 0.08786,
          "end_time": "2022-05-16T23:18:35.254344",
          "exception": false,
          "start_time": "2022-05-16T23:18:35.166484",
          "status": "completed"
        },
        "tags": [],
        "id": "ff7d7a2a"
      },
      "source": [
        "Transformers uses a `Dataset` object for storing a... well a dataset, of course! We can create one like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46fe2b83",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:35.438352Z",
          "iopub.status.busy": "2022-05-16T23:18:35.437675Z",
          "iopub.status.idle": "2022-05-16T23:18:37.535196Z",
          "shell.execute_reply": "2022-05-16T23:18:37.534706Z",
          "shell.execute_reply.started": "2022-04-19T22:50:25.267906Z"
        },
        "papermill": {
          "duration": 2.190631,
          "end_time": "2022-05-16T23:18:37.535330",
          "exception": false,
          "start_time": "2022-05-16T23:18:35.344699",
          "status": "completed"
        },
        "tags": [],
        "id": "46fe2b83"
      },
      "outputs": [],
      "source": [
        "ds = Dataset.from_pandas(df)\n",
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73bff7b1",
      "metadata": {
        "papermill": {
          "duration": 0.090915,
          "end_time": "2022-05-16T23:18:38.100934",
          "exception": false,
          "start_time": "2022-05-16T23:18:38.010019",
          "status": "completed"
        },
        "tags": [],
        "id": "73bff7b1"
      },
      "source": [
        "But we can't pass the texts directly into a model. A deep learning model expects numbers as inputs, not English sentences! So we need to do two things:\n",
        "\n",
        "- *Tokenization*: Split each text up into words (or actually, as we'll see, into *tokens*)\n",
        "- *Numericalization*: Convert each word (or token) into a number.\n",
        "\n",
        "The details about how this is done actually depend on the particular model we use. So first we'll need to pick a model. There are thousands of models available, but a reasonable starting point for nearly any NLP problem is to use this (replace \"small\" with \"large\" for a slower but more accurate model, once you've finished exploring):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f04956",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:38.291309Z",
          "iopub.status.busy": "2022-05-16T23:18:38.290399Z",
          "iopub.status.idle": "2022-05-16T23:18:38.292739Z",
          "shell.execute_reply": "2022-05-16T23:18:38.292199Z",
          "shell.execute_reply.started": "2022-04-19T22:50:27.345436Z"
        },
        "papermill": {
          "duration": 0.103204,
          "end_time": "2022-05-16T23:18:38.292884",
          "exception": false,
          "start_time": "2022-05-16T23:18:38.189680",
          "status": "completed"
        },
        "tags": [],
        "id": "94f04956"
      },
      "outputs": [],
      "source": [
        "model_nm = 'microsoft/deberta-v3-small'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8a437e9",
      "metadata": {
        "papermill": {
          "duration": 0.08842,
          "end_time": "2022-05-16T23:18:38.471586",
          "exception": false,
          "start_time": "2022-05-16T23:18:38.383166",
          "status": "completed"
        },
        "tags": [],
        "id": "f8a437e9"
      },
      "source": [
        "`AutoTokenizer` will create a tokenizer appropriate for a given model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a7191a0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:38.655835Z",
          "iopub.status.busy": "2022-05-16T23:18:38.655114Z",
          "iopub.status.idle": "2022-05-16T23:18:44.932165Z",
          "shell.execute_reply": "2022-05-16T23:18:44.931194Z",
          "shell.execute_reply.started": "2022-04-19T22:50:27.353989Z"
        },
        "papermill": {
          "duration": 6.371289,
          "end_time": "2022-05-16T23:18:44.932308",
          "exception": false,
          "start_time": "2022-05-16T23:18:38.561019",
          "status": "completed"
        },
        "tags": [],
        "id": "9a7191a0"
      },
      "outputs": [],
      "source": [
        "tokz = AutoTokenizer.from_pretrained(model_nm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd495e28",
      "metadata": {
        "papermill": {
          "duration": 0.095077,
          "end_time": "2022-05-16T23:18:45.131869",
          "exception": false,
          "start_time": "2022-05-16T23:18:45.036792",
          "status": "completed"
        },
        "tags": [],
        "id": "bd495e28"
      },
      "source": [
        "Here's an example of how the tokenizer splits a text into \"tokens\" (which are like words, but can be sub-word pieces, as you see below):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c972cb4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:45.320094Z",
          "iopub.status.busy": "2022-05-16T23:18:45.319492Z",
          "iopub.status.idle": "2022-05-16T23:18:45.322225Z",
          "shell.execute_reply": "2022-05-16T23:18:45.322660Z",
          "shell.execute_reply.started": "2022-04-19T22:50:32.889936Z"
        },
        "papermill": {
          "duration": 0.099704,
          "end_time": "2022-05-16T23:18:45.322809",
          "exception": false,
          "start_time": "2022-05-16T23:18:45.223105",
          "status": "completed"
        },
        "tags": [],
        "id": "2c972cb4"
      },
      "outputs": [],
      "source": [
        "tokz.tokenize(\"G'day folks, I'm Jeremy from fast.ai!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3d6eacc",
      "metadata": {
        "papermill": {
          "duration": 0.100207,
          "end_time": "2022-05-16T23:18:45.513113",
          "exception": false,
          "start_time": "2022-05-16T23:18:45.412906",
          "status": "completed"
        },
        "tags": [],
        "id": "e3d6eacc"
      },
      "source": [
        "Uncommon words will be split into pieces. The start of a new word is represented by `▁`:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b98a677",
      "metadata": {
        "papermill": {
          "duration": 0.090466,
          "end_time": "2022-05-16T23:18:45.892899",
          "exception": false,
          "start_time": "2022-05-16T23:18:45.802433",
          "status": "completed"
        },
        "tags": [],
        "id": "9b98a677"
      },
      "source": [
        "Here's a simple function which tokenizes our inputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b4df894",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:46.081044Z",
          "iopub.status.busy": "2022-05-16T23:18:46.079465Z",
          "iopub.status.idle": "2022-05-16T23:18:46.081698Z",
          "shell.execute_reply": "2022-05-16T23:18:46.082102Z",
          "shell.execute_reply.started": "2022-04-19T22:50:32.9125Z"
        },
        "papermill": {
          "duration": 0.098195,
          "end_time": "2022-05-16T23:18:46.082230",
          "exception": false,
          "start_time": "2022-05-16T23:18:45.984035",
          "status": "completed"
        },
        "tags": [],
        "id": "5b4df894"
      },
      "outputs": [],
      "source": [
        "def tok_func(x): return tokz(x[\"input\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc5b51f",
      "metadata": {
        "papermill": {
          "duration": 0.08984,
          "end_time": "2022-05-16T23:18:46.263955",
          "exception": false,
          "start_time": "2022-05-16T23:18:46.174115",
          "status": "completed"
        },
        "tags": [],
        "id": "5fc5b51f"
      },
      "source": [
        "To run this quickly in parallel on every row in our dataset, use `map`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dcae86d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:46.454144Z",
          "iopub.status.busy": "2022-05-16T23:18:46.453303Z",
          "iopub.status.idle": "2022-05-16T23:18:54.033052Z",
          "shell.execute_reply": "2022-05-16T23:18:54.032576Z",
          "shell.execute_reply.started": "2022-04-19T22:50:32.920244Z"
        },
        "papermill": {
          "duration": 7.678097,
          "end_time": "2022-05-16T23:18:54.033180",
          "exception": false,
          "start_time": "2022-05-16T23:18:46.355083",
          "status": "completed"
        },
        "tags": [],
        "id": "9dcae86d"
      },
      "outputs": [],
      "source": [
        "tok_ds = ds.map(tok_func, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dd77a16",
      "metadata": {
        "papermill": {
          "duration": 0.094896,
          "end_time": "2022-05-16T23:18:54.222495",
          "exception": false,
          "start_time": "2022-05-16T23:18:54.127599",
          "status": "completed"
        },
        "tags": [],
        "id": "0dd77a16"
      },
      "source": [
        "This adds a new item to our dataset called `input_ids`. For instance, here is the input and IDs for the first row of our data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef6401c5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:54.427236Z",
          "iopub.status.busy": "2022-05-16T23:18:54.426628Z",
          "iopub.status.idle": "2022-05-16T23:18:54.429396Z",
          "shell.execute_reply": "2022-05-16T23:18:54.429872Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.025726Z"
        },
        "papermill": {
          "duration": 0.10725,
          "end_time": "2022-05-16T23:18:54.430009",
          "exception": false,
          "start_time": "2022-05-16T23:18:54.322759",
          "status": "completed"
        },
        "tags": [],
        "id": "ef6401c5"
      },
      "outputs": [],
      "source": [
        "row = tok_ds[0]\n",
        "row['input'], row['input_ids']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5dafa61",
      "metadata": {
        "papermill": {
          "duration": 0.096597,
          "end_time": "2022-05-16T23:18:54.624153",
          "exception": false,
          "start_time": "2022-05-16T23:18:54.527556",
          "status": "completed"
        },
        "tags": [],
        "id": "b5dafa61"
      },
      "source": [
        "So, what are those IDs and where do they come from? The secret is that there's a list called `vocab` in the tokenizer which contains a unique integer for every possible token string. We can look them up like this, for instance to find the token for the word \"of\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d15fe108",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:54.834285Z",
          "iopub.status.busy": "2022-05-16T23:18:54.833617Z",
          "iopub.status.idle": "2022-05-16T23:18:54.836600Z",
          "shell.execute_reply": "2022-05-16T23:18:54.837081Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.035118Z"
        },
        "papermill": {
          "duration": 0.114718,
          "end_time": "2022-05-16T23:18:54.837222",
          "exception": false,
          "start_time": "2022-05-16T23:18:54.722504",
          "status": "completed"
        },
        "tags": [],
        "id": "d15fe108"
      },
      "outputs": [],
      "source": [
        "tokz.vocab['▁of']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb58e8bc",
      "metadata": {
        "papermill": {
          "duration": 0.105436,
          "end_time": "2022-05-16T23:18:55.050112",
          "exception": false,
          "start_time": "2022-05-16T23:18:54.944676",
          "status": "completed"
        },
        "tags": [],
        "id": "eb58e8bc"
      },
      "source": [
        "Finally, we need to prepare our labels. Transformers always assumes that your labels has the column name `labels`, but in our dataset it's currently `score`. Therefore, we need to rename it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1872e8aa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:55.247145Z",
          "iopub.status.busy": "2022-05-16T23:18:55.246268Z",
          "iopub.status.idle": "2022-05-16T23:18:55.249927Z",
          "shell.execute_reply": "2022-05-16T23:18:55.249454Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.045156Z"
        },
        "papermill": {
          "duration": 0.101969,
          "end_time": "2022-05-16T23:18:55.250039",
          "exception": false,
          "start_time": "2022-05-16T23:18:55.148070",
          "status": "completed"
        },
        "tags": [],
        "id": "1872e8aa"
      },
      "outputs": [],
      "source": [
        "tok_ds = tok_ds.rename_columns({'score':'labels'})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66c7a56c",
      "metadata": {
        "papermill": {
          "duration": 0.091929,
          "end_time": "2022-05-16T23:18:55.616679",
          "exception": false,
          "start_time": "2022-05-16T23:18:55.524750",
          "status": "completed"
        },
        "tags": [],
        "id": "66c7a56c"
      },
      "source": [
        "## Test and validation sets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64dd7b30",
      "metadata": {
        "papermill": {
          "duration": 0.105152,
          "end_time": "2022-05-16T23:18:55.814337",
          "exception": false,
          "start_time": "2022-05-16T23:18:55.709185",
          "status": "completed"
        },
        "tags": [],
        "id": "64dd7b30"
      },
      "source": [
        "You may have noticed that our directory contained another file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53780c56",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:18:56.029583Z",
          "iopub.status.busy": "2022-05-16T23:18:56.028954Z",
          "iopub.status.idle": "2022-05-16T23:18:56.049673Z",
          "shell.execute_reply": "2022-05-16T23:18:56.050181Z",
          "shell.execute_reply.started": "2022-04-19T22:50:40.055398Z"
        },
        "papermill": {
          "duration": 0.130433,
          "end_time": "2022-05-16T23:18:56.050339",
          "exception": false,
          "start_time": "2022-05-16T23:18:55.919906",
          "status": "completed"
        },
        "tags": [],
        "id": "53780c56"
      },
      "outputs": [],
      "source": [
        "eval_df = pd.read_csv(path/'test.csv')\n",
        "eval_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b72de683",
      "metadata": {
        "papermill": {
          "duration": 0.093872,
          "end_time": "2022-05-16T23:18:56.237423",
          "exception": false,
          "start_time": "2022-05-16T23:18:56.143551",
          "status": "completed"
        },
        "tags": [],
        "id": "b72de683"
      },
      "source": [
        "This is the *test set*. Possibly the most important idea in machine learning is that of having separate ***training, validation, and test*** data sets."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c80d0906",
      "metadata": {
        "heading_collapsed": true,
        "papermill": {
          "duration": 0.091766,
          "end_time": "2022-05-16T23:18:56.421195",
          "exception": false,
          "start_time": "2022-05-16T23:18:56.329429",
          "status": "completed"
        },
        "tags": [],
        "id": "c80d0906"
      },
      "source": [
        "### Validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4789f92a",
      "metadata": {
        "hidden": true,
        "papermill": {
          "duration": 0.096446,
          "end_time": "2022-05-16T23:19:02.537038",
          "exception": false,
          "start_time": "2022-05-16T23:19:02.440592",
          "status": "completed"
        },
        "tags": [],
        "id": "4789f92a"
      },
      "source": [
        "How do we recognise whether our models are under-fit, over-fit, or \"just right\"? We use a *validation set*. This is a set of data that we \"hold out\" from training -- we don't let our model see it at all. If you use the fastai library, it automatically creates a validation set for you if you don't have one, and will always report metrics (measurements of the accuracy of a model) using the validation set.\n",
        "\n",
        "The validation set is *only* ever used to see how we're doing. It's *never* used as inputs to training the model.\n",
        "\n",
        "Transformers uses a `DatasetDict` for holding your training and validation sets. To create one that contains 25% of our data for the validation set, and 75% for the training set, use `train_test_split`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8b1e366",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:19:02.734895Z",
          "iopub.status.busy": "2022-05-16T23:19:02.734114Z",
          "iopub.status.idle": "2022-05-16T23:19:02.754237Z",
          "shell.execute_reply": "2022-05-16T23:19:02.754678Z",
          "shell.execute_reply.started": "2022-04-19T22:50:42.182674Z"
        },
        "hidden": true,
        "papermill": {
          "duration": 0.122148,
          "end_time": "2022-05-16T23:19:02.754828",
          "exception": false,
          "start_time": "2022-05-16T23:19:02.632680",
          "status": "completed"
        },
        "tags": [],
        "id": "b8b1e366"
      },
      "outputs": [],
      "source": [
        "dds = tok_ds.train_test_split(0.25, seed=42)\n",
        "dds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "776f4394",
      "metadata": {
        "hidden": true,
        "papermill": {
          "duration": 0.096073,
          "end_time": "2022-05-16T23:19:02.948686",
          "exception": false,
          "start_time": "2022-05-16T23:19:02.852613",
          "status": "completed"
        },
        "tags": [],
        "id": "776f4394"
      },
      "source": [
        "As you see above, the validation set here is called `test` and not `validate`, so be careful!\n",
        "\n",
        "In practice, a random split like we've used here might not be a good idea -- here's what Dr Rachel Thomas has to say about it:\n",
        "\n",
        "> \"*One of the most likely culprits for this disconnect between results in development vs results in production is a poorly chosen validation set (or even worse, no validation set at all). Depending on the nature of your data, choosing a validation set can be the most important step. Although sklearn offers a `train_test_split` method, this method takes a random subset of the data, which is a poor choice for many real-world problems.*\"\n",
        "\n",
        "I strongly recommend reading her article [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/) to more fully understand this critical topic."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc1f53c9",
      "metadata": {
        "heading_collapsed": true,
        "papermill": {
          "duration": 0.096584,
          "end_time": "2022-05-16T23:19:03.142638",
          "exception": false,
          "start_time": "2022-05-16T23:19:03.046054",
          "status": "completed"
        },
        "tags": [],
        "id": "dc1f53c9"
      },
      "source": [
        "### Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e665eb75",
      "metadata": {
        "hidden": true,
        "papermill": {
          "duration": 0.10414,
          "end_time": "2022-05-16T23:19:03.343573",
          "exception": false,
          "start_time": "2022-05-16T23:19:03.239433",
          "status": "completed"
        },
        "tags": [],
        "id": "e665eb75"
      },
      "source": [
        "So that's the validation set explained, and created. What about the \"test set\" then -- what's that for?\n",
        "\n",
        "The *test set* is yet another dataset that's held out from training. But it's held out from reporting metrics too! The accuracy of your model on the test set is only ever checked after you've completed your entire training process, including trying different models, training methods, data processing, etc.\n",
        "\n",
        "You see, as you try all these different things, to see their impact on the metrics on the validation set, you might just accidentally find a few things that entirely coincidentally improve your validation set metrics, but aren't really better in practice. Given enough time and experiments, you'll find lots of these coincidental improvements. That means you're actually over-fitting to your validation set!\n",
        "\n",
        "That's why we keep a test set held back. Kaggle's public leaderboard is like a test set that you can check from time to time. But don't check too often, or you'll be even over-fitting to the test set!\n",
        "\n",
        "Kaggle has a *second* test set, which is yet another held-out dataset that's only used at the *end* of the competition to assess your predictions. That's called the \"private leaderboard\". Here's a [great post](https://gregpark.io/blog/Kaggle-Psychopathy-Postmortem/) about what can happen if you overfit to the public leaderboard.\n",
        "\n",
        "We'll use `eval` as our name for the test set, to avoid confusion with the `test` dataset that was created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a064b7f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:19:03.544188Z",
          "iopub.status.busy": "2022-05-16T23:19:03.543651Z",
          "iopub.status.idle": "2022-05-16T23:19:04.825203Z",
          "shell.execute_reply": "2022-05-16T23:19:04.823967Z",
          "shell.execute_reply.started": "2022-04-19T22:50:42.209113Z"
        },
        "hidden": true,
        "papermill": {
          "duration": 1.38502,
          "end_time": "2022-05-16T23:19:04.825395",
          "exception": false,
          "start_time": "2022-05-16T23:19:03.440375",
          "status": "completed"
        },
        "tags": [],
        "id": "3a064b7f"
      },
      "outputs": [],
      "source": [
        "eval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\n",
        "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a782e55e",
      "metadata": {
        "heading_collapsed": true,
        "papermill": {
          "duration": 0.109004,
          "end_time": "2022-05-16T23:19:05.050664",
          "exception": false,
          "start_time": "2022-05-16T23:19:04.941660",
          "status": "completed"
        },
        "tags": [],
        "id": "a782e55e"
      },
      "source": [
        "## Metrics and correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afde9fc3",
      "metadata": {
        "hidden": true,
        "papermill": {
          "duration": 0.097068,
          "end_time": "2022-05-16T23:19:05.244731",
          "exception": false,
          "start_time": "2022-05-16T23:19:05.147663",
          "status": "completed"
        },
        "tags": [],
        "id": "afde9fc3"
      },
      "source": [
        "When we're training a model, there will be one or more *metrics* that we're interested in maximising or minimising. These are the measurements that should, hopefully, represent how well our model will works for us.\n",
        "\n",
        "In real life, outside of Kaggle, things not easy... As my partner Dr Rachel Thomas notes in [The problem with metrics is a big problem for AI](https://www.fast.ai/2019/09/24/metrics/):\n",
        "\n",
        ">  At their heart, what most current AI approaches do is to optimize metrics. The practice of optimizing metrics is not new nor unique to AI, yet AI can be particularly efficient (even too efficient!) at doing so. This is important to understand, because any risks of optimizing metrics are heightened by AI. While metrics can be useful in their proper place, there are harms when they are unthinkingly applied. Some of the scariest instances of algorithms run amok all result from over-emphasizing metrics. We have to understand this dynamic in order to understand the urgent risks we are facing due to misuse of AI.\n",
        "\n",
        "In Kaggle, however, it's very straightforward to know what metric to use: Kaggle will tell you! According to this competition's [evaluation page](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/overview/evaluation), \"*submissions are evaluated on the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) between the predicted and actual similarity scores*.\" This coefficient is usually abbreviated using the single letter *r*. It is the most widely used measure of the degree of relationship between two variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8565840d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:19:09.137395Z",
          "iopub.status.busy": "2022-05-16T23:19:09.136447Z",
          "iopub.status.idle": "2022-05-16T23:19:09.139903Z",
          "shell.execute_reply": "2022-05-16T23:19:09.140273Z",
          "shell.execute_reply.started": "2022-04-19T22:50:45.716828Z"
        },
        "hidden": true,
        "papermill": {
          "duration": 0.108235,
          "end_time": "2022-05-16T23:19:09.140419",
          "exception": false,
          "start_time": "2022-05-16T23:19:09.032184",
          "status": "completed"
        },
        "tags": [],
        "id": "8565840d"
      },
      "outputs": [],
      "source": [
        "def corr(x,y): return np.corrcoef(x,y)[0][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce158a24",
      "metadata": {
        "hidden": true,
        "papermill": {
          "duration": 0.103658,
          "end_time": "2022-05-16T23:19:13.401756",
          "exception": false,
          "start_time": "2022-05-16T23:19:13.298098",
          "status": "completed"
        },
        "tags": [],
        "id": "ce158a24"
      },
      "source": [
        "Transformers expects metrics to be returned as a `dict`, since that way the trainer knows what label to use, so let's create a function to do that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5ff917b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:19:13.612237Z",
          "iopub.status.busy": "2022-05-16T23:19:13.611377Z",
          "iopub.status.idle": "2022-05-16T23:19:13.614160Z",
          "shell.execute_reply": "2022-05-16T23:19:13.613658Z",
          "shell.execute_reply.started": "2022-04-19T22:50:46.715707Z"
        },
        "hidden": true,
        "papermill": {
          "duration": 0.109782,
          "end_time": "2022-05-16T23:19:13.614283",
          "exception": false,
          "start_time": "2022-05-16T23:19:13.504501",
          "status": "completed"
        },
        "tags": [],
        "id": "a5ff917b"
      },
      "outputs": [],
      "source": [
        "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}\n",
        "# what does the eval_pred look like? which function returns it?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "352007a6",
      "metadata": {
        "papermill": {
          "duration": 0.118052,
          "end_time": "2022-05-16T23:19:14.047292",
          "exception": false,
          "start_time": "2022-05-16T23:19:13.929240",
          "status": "completed"
        },
        "tags": [],
        "id": "352007a6"
      },
      "source": [
        "## Training our model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bef40f65",
      "metadata": {
        "papermill": {
          "duration": 0.103363,
          "end_time": "2022-05-16T23:19:19.125535",
          "exception": false,
          "start_time": "2022-05-16T23:19:19.022172",
          "status": "completed"
        },
        "tags": [],
        "id": "bef40f65"
      },
      "source": [
        "We pick a batch size that fits our GPU, and small number of epochs so we can run experiments quickly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a7f73b8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:19:19.336295Z",
          "iopub.status.busy": "2022-05-16T23:19:19.334700Z",
          "iopub.status.idle": "2022-05-16T23:19:19.336896Z",
          "shell.execute_reply": "2022-05-16T23:19:19.337294Z",
          "shell.execute_reply.started": "2022-04-19T22:50:50.493351Z"
        },
        "papermill": {
          "duration": 0.109762,
          "end_time": "2022-05-16T23:19:19.337450",
          "exception": false,
          "start_time": "2022-05-16T23:19:19.227688",
          "status": "completed"
        },
        "tags": [],
        "id": "9a7f73b8"
      },
      "outputs": [],
      "source": [
        "bs = 128\n",
        "epochs = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b9defba",
      "metadata": {
        "papermill": {
          "duration": 0.104127,
          "end_time": "2022-05-16T23:19:19.544960",
          "exception": false,
          "start_time": "2022-05-16T23:19:19.440833",
          "status": "completed"
        },
        "tags": [],
        "id": "1b9defba"
      },
      "source": [
        "The most important hyperparameter is the learning rate. fastai provides a learning rate finder to help you figure this out, but Transformers doesn't, so you'll just have to use trial and error. The idea is to find the largest value you can, but which doesn't result in training failing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d56aa8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:19:19.756018Z",
          "iopub.status.busy": "2022-05-16T23:19:19.755174Z",
          "iopub.status.idle": "2022-05-16T23:19:19.757522Z",
          "shell.execute_reply": "2022-05-16T23:19:19.756988Z",
          "shell.execute_reply.started": "2022-04-19T22:50:50.499493Z"
        },
        "papermill": {
          "duration": 0.109843,
          "end_time": "2022-05-16T23:19:19.757641",
          "exception": false,
          "start_time": "2022-05-16T23:19:19.647798",
          "status": "completed"
        },
        "tags": [],
        "id": "95d56aa8"
      },
      "outputs": [],
      "source": [
        "lr = 8e-5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456eba4a",
      "metadata": {
        "papermill": {
          "duration": 0.104473,
          "end_time": "2022-05-16T23:19:19.964659",
          "exception": false,
          "start_time": "2022-05-16T23:19:19.860186",
          "status": "completed"
        },
        "tags": [],
        "id": "456eba4a"
      },
      "source": [
        "Transformers uses the `TrainingArguments` class to set up arguments. Don't worry too much about the values we're using here -- they should generally work fine in most cases. It's just the 3 parameters above that you may need to change for different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e009173f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:19:20.241601Z",
          "iopub.status.busy": "2022-05-16T23:19:20.178470Z",
          "iopub.status.idle": "2022-05-16T23:19:20.247751Z",
          "shell.execute_reply": "2022-05-16T23:19:20.247289Z",
          "shell.execute_reply.started": "2022-04-19T22:50:50.511653Z"
        },
        "papermill": {
          "duration": 0.178531,
          "end_time": "2022-05-16T23:19:20.247877",
          "exception": false,
          "start_time": "2022-05-16T23:19:20.069346",
          "status": "completed"
        },
        "tags": [],
        "id": "e009173f"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    'outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine',\n",
        "    fp16=True, eval_strategy=\"epoch\", per_device_train_batch_size=bs,\n",
        "    per_device_eval_batch_size=bs*2,num_train_epochs=epochs, weight_decay=0.01,\n",
        "    report_to='none')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6f09673",
      "metadata": {
        "papermill": {
          "duration": 0.10325,
          "end_time": "2022-05-16T23:19:20.455326",
          "exception": false,
          "start_time": "2022-05-16T23:19:20.352076",
          "status": "completed"
        },
        "tags": [],
        "id": "c6f09673"
      },
      "source": [
        "We can now create our model, and `Trainer`, which is a class which combines the data and model together (just like `Learner` in fastai):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c242e16d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:19:20.669564Z",
          "iopub.status.busy": "2022-05-16T23:19:20.668967Z",
          "iopub.status.idle": "2022-05-16T23:19:41.632888Z",
          "shell.execute_reply": "2022-05-16T23:19:41.632215Z",
          "shell.execute_reply.started": "2022-04-19T22:50:50.57276Z"
        },
        "papermill": {
          "duration": 21.075395,
          "end_time": "2022-05-16T23:19:41.633043",
          "exception": false,
          "start_time": "2022-05-16T23:19:20.557648",
          "status": "completed"
        },
        "tags": [],
        "id": "c242e16d"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_nm, num_labels=1\n",
        "    )\n",
        "trainer = Trainer(\n",
        "    model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
        "    tokenizer=tokz, compute_metrics=corr_d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e88b0728",
      "metadata": {
        "papermill": {
          "duration": 0.103838,
          "end_time": "2022-05-16T23:19:41.843310",
          "exception": false,
          "start_time": "2022-05-16T23:19:41.739472",
          "status": "completed"
        },
        "tags": [],
        "id": "e88b0728"
      },
      "source": [
        "As you see, Transformers spits out lots of warnings. You can safely ignore them.\n",
        "\n",
        "Let's train our model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a8f21fc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:19:42.058507Z",
          "iopub.status.busy": "2022-05-16T23:19:42.057901Z",
          "iopub.status.idle": "2022-05-16T23:24:41.844317Z",
          "shell.execute_reply": "2022-05-16T23:24:41.843875Z",
          "shell.execute_reply.started": "2022-04-19T22:51:06.370314Z"
        },
        "papermill": {
          "duration": 299.896532,
          "end_time": "2022-05-16T23:24:41.844469",
          "exception": false,
          "start_time": "2022-05-16T23:19:41.947937",
          "status": "completed"
        },
        "tags": [],
        "id": "1a8f21fc"
      },
      "outputs": [],
      "source": [
        "trainer.train();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f71e4a43",
      "metadata": {
        "papermill": {
          "duration": 0.128839,
          "end_time": "2022-05-16T23:24:42.089146",
          "exception": false,
          "start_time": "2022-05-16T23:24:41.960307",
          "status": "completed"
        },
        "tags": [],
        "id": "f71e4a43"
      },
      "source": [
        "The key thing to look at is the \"Pearson\" value in table above. As you see, it's increasing, and is already above 0.8. That's great news! We can now submit our predictions to Kaggle if we want them to be scored on the official leaderboard. Let's get some predictions on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc9ff8a9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:24:42.337547Z",
          "iopub.status.busy": "2022-05-16T23:24:42.336666Z",
          "iopub.status.idle": "2022-05-16T23:24:42.387175Z",
          "shell.execute_reply": "2022-05-16T23:24:42.387621Z",
          "shell.execute_reply.started": "2022-04-19T22:56:03.886175Z"
        },
        "papermill": {
          "duration": 0.176198,
          "end_time": "2022-05-16T23:24:42.387780",
          "exception": false,
          "start_time": "2022-05-16T23:24:42.211582",
          "status": "completed"
        },
        "tags": [],
        "id": "cc9ff8a9"
      },
      "outputs": [],
      "source": [
        "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
        "preds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7f99fe2",
      "metadata": {
        "papermill": {
          "duration": 0.118083,
          "end_time": "2022-05-16T23:24:42.627541",
          "exception": false,
          "start_time": "2022-05-16T23:24:42.509458",
          "status": "completed"
        },
        "tags": [],
        "id": "e7f99fe2"
      },
      "source": [
        "Look out - some of our predictions are <0, or >1! This once again shows the value of remember to actually *look* at your data. Let's fix those out-of-bounds predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87e31c26",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:24:42.887528Z",
          "iopub.status.busy": "2022-05-16T23:24:42.886610Z",
          "iopub.status.idle": "2022-05-16T23:24:42.888262Z",
          "shell.execute_reply": "2022-05-16T23:24:42.888836Z",
          "shell.execute_reply.started": "2022-04-19T22:56:03.940986Z"
        },
        "papermill": {
          "duration": 0.130653,
          "end_time": "2022-05-16T23:24:42.888988",
          "exception": false,
          "start_time": "2022-05-16T23:24:42.758335",
          "status": "completed"
        },
        "tags": [],
        "id": "87e31c26"
      },
      "outputs": [],
      "source": [
        "preds = np.clip(preds, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ce77ef",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:24:43.130852Z",
          "iopub.status.busy": "2022-05-16T23:24:43.130226Z",
          "iopub.status.idle": "2022-05-16T23:24:43.133011Z",
          "shell.execute_reply": "2022-05-16T23:24:43.133433Z",
          "shell.execute_reply.started": "2022-04-19T22:56:03.946586Z"
        },
        "papermill": {
          "duration": 0.126485,
          "end_time": "2022-05-16T23:24:43.133567",
          "exception": false,
          "start_time": "2022-05-16T23:24:43.007082",
          "status": "completed"
        },
        "tags": [],
        "id": "73ce77ef"
      },
      "outputs": [],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "613fd9ce",
      "metadata": {
        "papermill": {
          "duration": 0.1167,
          "end_time": "2022-05-16T23:24:43.367254",
          "exception": false,
          "start_time": "2022-05-16T23:24:43.250554",
          "status": "completed"
        },
        "tags": [],
        "id": "613fd9ce"
      },
      "source": [
        "OK, now we're ready to create our submission file. If you save a CSV in your notebook, you will get the option to submit it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b89fb1f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-16T23:24:43.662645Z",
          "iopub.status.busy": "2022-05-16T23:24:43.661829Z",
          "iopub.status.idle": "2022-05-16T23:24:43.714350Z",
          "shell.execute_reply": "2022-05-16T23:24:43.712706Z",
          "shell.execute_reply.started": "2022-04-19T22:56:03.959351Z"
        },
        "papermill": {
          "duration": 0.173814,
          "end_time": "2022-05-16T23:24:43.714480",
          "exception": false,
          "start_time": "2022-05-16T23:24:43.540666",
          "status": "completed"
        },
        "tags": [],
        "id": "7b89fb1f"
      },
      "outputs": [],
      "source": [
        "# import datasets\n",
        "\n",
        "# submission = datasets.Dataset.from_dict({\n",
        "#     'id': eval_ds['id'],\n",
        "#     'score': preds\n",
        "# })\n",
        "\n",
        "# submission.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4b0e3cf",
      "metadata": {
        "papermill": {
          "duration": 0.118094,
          "end_time": "2022-05-16T23:24:43.950959",
          "exception": false,
          "start_time": "2022-05-16T23:24:43.832865",
          "status": "completed"
        },
        "tags": [],
        "id": "b4b0e3cf"
      },
      "source": [
        "Unfortunately this is a *code competition* and internet access is disabled. That means the `pip install datasets` command we used above won't work if you want to submit to Kaggle. To fix this, you'll need to download the pip installers to Kaggle first, as [described here](https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/113195). Once you've done that, disable internet in your notebook, go to the Kaggle leaderboards page, and click the *Submission* button."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 396.918297,
      "end_time": "2022-05-16T23:24:47.551396",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-05-16T23:18:10.633099",
      "version": "2.3.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}