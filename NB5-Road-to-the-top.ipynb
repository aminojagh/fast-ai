{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminojagh/fast-ai/blob/main/NB5-Road-to-the-top.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c6bBVKEKVtR",
      "metadata": {
        "id": "2c6bBVKEKVtR"
      },
      "source": [
        "## Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dXBgRr4KEXw4",
      "metadata": {
        "id": "dXBgRr4KEXw4"
      },
      "source": [
        "using fastkaggle to setup the competition (requires ~/kaggle/kaggle.json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RcE_XjULHmF9",
      "metadata": {
        "id": "RcE_XjULHmF9"
      },
      "outputs": [],
      "source": [
        "kaggle_config_path = '/root/.config/kaggle'\n",
        "!mkdir {kaggle_config_path}\n",
        "from google.colab import files\n",
        "files.upload(kaggle_config_path)\n",
        "!chmod 600 /root/.config/kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbwxp1jhHyVO",
      "metadata": {
        "id": "cbwxp1jhHyVO"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq fastkaggle fastai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zpPVdJX7TAqX",
      "metadata": {
        "id": "zpPVdJX7TAqX"
      },
      "outputs": [],
      "source": [
        "from fastkaggle import setup_comp, iskaggle, push_notebook\n",
        "from fastai.vision.all import (get_image_files, PILImage, set_seed,\n",
        "                               ImageDataLoaders, Resize, aug_transforms,\n",
        "                               vision_learner, error_rate, valley, slide)\n",
        "\n",
        "from fastcore.parallel import parallel\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fg4fLfOqD1AI",
      "metadata": {
        "id": "Fg4fLfOqD1AI"
      },
      "outputs": [],
      "source": [
        "comp = 'paddy-disease-classification'\n",
        "path = setup_comp(comp, install='fastai \"timm>=0.6.2.dev0\"')\n",
        "print(path)\n",
        "display(path.ls())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MgE3YcajKeVB",
      "metadata": {
        "id": "MgE3YcajKeVB"
      },
      "source": [
        "## Looaking at the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sl7iFTEFKySt",
      "metadata": {
        "id": "sl7iFTEFKySt"
      },
      "outputs": [],
      "source": [
        "trn_path = path/'train_images'\n",
        "files = get_image_files(trn_path)\n",
        "# img = PILImage.create(files[0])\n",
        "# print(img.size)\n",
        "# img.to_thumb(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FTwSoXQSLEW7",
      "metadata": {
        "id": "FTwSoXQSLEW7"
      },
      "outputs": [],
      "source": [
        "def f(o): return PILImage.create(o).size\n",
        "sizes = parallel(f, files, n_workers=8)\n",
        "pd.Series(sizes).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C549CBXIHq2s",
      "metadata": {
        "id": "C549CBXIHq2s"
      },
      "outputs": [],
      "source": [
        "dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, seed=42,\n",
        "    item_tfms=Resize(480, method='squish'),\n",
        "    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n",
        "\n",
        "# dls.show_batch(max_n=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Zhv4B_16IQfe",
      "metadata": {
        "id": "Zhv4B_16IQfe"
      },
      "source": [
        "## Our first model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "URFmFdWxIB7p",
      "metadata": {
        "id": "URFmFdWxIB7p"
      },
      "outputs": [],
      "source": [
        "learn = vision_learner(dls, 'resnet26d', metrics=error_rate, path='.').to_fp16()\n",
        "learn.lr_find(suggest_funcs=(valley, slide))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6rpsquXeIWdo",
      "metadata": {
        "id": "6rpsquXeIWdo"
      },
      "outputs": [],
      "source": [
        "learn.fine_tune(3, 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jq_NojrkJauM",
      "metadata": {
        "id": "jq_NojrkJauM"
      },
      "source": [
        "## Submitting to Kaggle-I"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qcjwbiD7KrzQ",
      "metadata": {
        "id": "qcjwbiD7KrzQ"
      },
      "outputs": [],
      "source": [
        "ss = pd.read_csv(path/'sample_submission.csv')\n",
        "tst_files = get_image_files(path/'test_images').sorted()\n",
        "tst_dl = dls.test_dl(tst_files)\n",
        "\n",
        "probs,_,idxs = learn.get_preds(dl=tst_dl, with_decoded=True)\n",
        "# print(idxs)\n",
        "# print(dls.vocab)\n",
        "mapping = dict(enumerate(dls.vocab))\n",
        "results = pd.Series(idxs.numpy(), name=\"idxs\").map(mapping)\n",
        "\n",
        "ss['label'] = results\n",
        "ss.to_csv('subm.csv', index=False)\n",
        "# !head subm.csv\n",
        "\n",
        "if not iskaggle:\n",
        "    from kaggle import api\n",
        "    api.competition_submit_cli('subm.csv', 'initial rn26d 128px', comp)\n",
        "    # push_notebook('jhoward', 'first-steps-road-to-the-top-part-1',\n",
        "    #               title='First Steps: Road to the Top, Part 1',\n",
        "    #               file='first-steps-road-to-the-top-part-1.ipynb',\n",
        "    #               competition=comp, private=False, gpu=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KybsWmeSU8Bz",
      "metadata": {
        "id": "KybsWmeSU8Bz"
      },
      "source": [
        "## Going faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45VKhRw9U8iF",
      "metadata": {
        "id": "45VKhRw9U8iF"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from fastai.vision.all import resize_images, ResizeMethod, PadMode\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-MTE4CxqYwKX",
      "metadata": {
        "id": "-MTE4CxqYwKX"
      },
      "outputs": [],
      "source": [
        "trn_path = Path('sml')\n",
        "resize_images(path/'train_images', dest=trn_path, max_size=256, recurse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ka7mk_MuVdRa",
      "metadata": {
        "id": "Ka7mk_MuVdRa"
      },
      "outputs": [],
      "source": [
        "def train(trn_path, arch, item, batch, epochs=5):\n",
        "    dls = ImageDataLoaders.from_folder(trn_path, seed=42, valid_pct=0.2, item_tfms=item, batch_tfms=batch)\n",
        "    learn = vision_learner(dls, arch, metrics=error_rate).to_fp16()\n",
        "    learn.fine_tune(epochs, 0.01)\n",
        "    return learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-qc63M_gcNtP",
      "metadata": {
        "id": "-qc63M_gcNtP"
      },
      "outputs": [],
      "source": [
        "# # our initial model\n",
        "# learn = train(trn_path,\n",
        "#               'resnet26d',\n",
        "#               item=Resize(192),\n",
        "#               batch=aug_transforms(size=128, min_scale=0.75))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A-731ARwWm7L",
      "metadata": {
        "id": "A-731ARwWm7L"
      },
      "source": [
        "## A ConvNeXt model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2iBX79kVWnpB",
      "metadata": {
        "id": "2iBX79kVWnpB"
      },
      "outputs": [],
      "source": [
        "arch = 'convnext_small_in22k'\n",
        "\n",
        "# learn = train(trn_path,\n",
        "#               arch,\n",
        "#               item=Resize(192, method='squish'), # the default method is 'crop'\n",
        "#               batch=aug_transforms(size=128, min_scale=0.75))\n",
        "\n",
        "learn = train(trn_path,\n",
        "              arch,\n",
        "              item=Resize((256,192),\n",
        "                          method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n",
        "              batch=aug_transforms(size=(171,128), min_scale=0.75))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lot2dUyqW4cc",
      "metadata": {
        "id": "lot2dUyqW4cc"
      },
      "source": [
        "## Test time augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5QgEZ_PnW5LH",
      "metadata": {
        "id": "5QgEZ_PnW5LH"
      },
      "outputs": [],
      "source": [
        "valid = learn.dls.valid\n",
        "preds,targs = learn.get_preds(dl=valid)\n",
        "error_rate(preds, targs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fJs5sk-OcA76",
      "metadata": {
        "id": "fJs5sk-OcA76"
      },
      "outputs": [],
      "source": [
        "tta_preds,_ = learn.tta(dl=valid)\n",
        "error_rate(tta_preds, targs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vGCG_Bb8XAHA",
      "metadata": {
        "id": "vGCG_Bb8XAHA"
      },
      "source": [
        "## Scaling up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YMM93b06XAmQ",
      "metadata": {
        "id": "YMM93b06XAmQ"
      },
      "outputs": [],
      "source": [
        "trn_path = path/'train_images'\n",
        "\n",
        "learn = train(trn_path,\n",
        "              arch,\n",
        "              epochs=12,\n",
        "              item=Resize((480, 360), method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n",
        "              batch=aug_transforms(size=(256,192), min_scale=0.75))\n",
        "\n",
        "tta_preds,targs = learn.tta(dl=learn.dls.valid)\n",
        "error_rate(tta_preds, targs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rs8n3_fOXJnR",
      "metadata": {
        "id": "rs8n3_fOXJnR"
      },
      "source": [
        "## Submitting to Kaggle-II"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Maju8a3vjb68",
      "metadata": {
        "id": "Maju8a3vjb68"
      },
      "outputs": [],
      "source": [
        "def submit_to_kaggle(sample_sub_file_path:Path,\n",
        "                     test_images_path:Path,\n",
        "                     iskaggle:bool, tta:bool,\n",
        "                     sub_title:str\n",
        "                     ):\n",
        "\n",
        "  ss = pd.read_csv(sample_sub_file_path)\n",
        "  tst_files = get_image_files(test_images_path).sorted()\n",
        "  tst_dl = learn.dls.test_dl(tst_files)\n",
        "\n",
        "  if tta:\n",
        "    preds,_ = learn.tta(dl=tst_dl)\n",
        "    idxs = preds.argmax(dim=1)\n",
        "  else:\n",
        "    probs,_,idxs = learn.get_preds(dl=tst_dl, with_decoded=True)\n",
        "\n",
        "  vocab = np.array(learn.dls.vocab)\n",
        "  results = pd.Series(vocab[idxs], name=\"idxs\")\n",
        "\n",
        "\n",
        "  ss['label'] = results\n",
        "  ss.to_csv('subm.csv', index=False)\n",
        "\n",
        "  if not iskaggle:\n",
        "      from kaggle import api\n",
        "      api.competition_submit_cli('subm.csv', sub_title, comp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-24-ITauXK8E",
      "metadata": {
        "id": "-24-ITauXK8E"
      },
      "outputs": [],
      "source": [
        "submit_to_kaggle(sample_sub_file_path = path/'sample_submission.csv',\n",
        "                 test_images_path = path/'test_images',\n",
        "                 iskaggle = iskaggle, tta = True,\n",
        "                 sub_title = 'convnext small 256x192 12 epochs tta')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76e3c867",
      "metadata": {},
      "source": [
        "## Memory and gradient accumulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S-NCG1JJqBX7",
      "metadata": {
        "id": "S-NCG1JJqBX7"
      },
      "outputs": [],
      "source": [
        "tst_files = get_image_files(path/'test_images').sorted()\n",
        "df = pd.read_csv(path/'train.csv')\n",
        "df.label.value_counts()\n",
        "trn_path = path/'train_images'/'bacterial_panicle_blight'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae4cefea",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(arch, size, item=Resize(480, method='squish'), accum=1, finetune=True, epochs=12):\n",
        "    dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, item_tfms=item,\n",
        "        batch_tfms=aug_transforms(size=size, min_scale=0.75), bs=64//accum)\n",
        "    cbs = GradientAccumulation(64) if accum else []\n",
        "    learn = vision_learner(dls, arch, metrics=error_rate, cbs=cbs).to_fp16()\n",
        "    if finetune:\n",
        "        learn.fine_tune(epochs, 0.01)\n",
        "        return learn.tta(dl=dls.test_dl(tst_files))\n",
        "    else:\n",
        "        learn.unfreeze()\n",
        "        learn.fit_one_cycle(epochs, 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6cd2941",
      "metadata": {},
      "source": [
        "## Checking memory use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b8ddf7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "def report_gpu():\n",
        "    print(torch.cuda.list_gpu_processes())\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7d07972",
      "metadata": {},
      "outputs": [],
      "source": [
        "train('convnext_small_in22k', 128, epochs=1, accum=1, finetune=False)\n",
        "report_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7c0c604",
      "metadata": {},
      "outputs": [],
      "source": [
        "train('convnext_small_in22k', 128, epochs=1, accum=2, finetune=False)\n",
        "report_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8921fb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "train('convnext_small_in22k', 128, epochs=1, accum=4, finetune=False)\n",
        "report_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b118efad",
      "metadata": {},
      "outputs": [],
      "source": [
        "train('convnext_large_in22k', 224, epochs=1, accum=2, finetune=False)\n",
        "report_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c1491f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "train('convnext_large_in22k', (320,240), epochs=1, accum=2, finetune=False)\n",
        "report_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5986b94c",
      "metadata": {},
      "outputs": [],
      "source": [
        "train('vit_large_patch16_224', 224, epochs=1, accum=2, finetune=False)\n",
        "report_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73448fc7",
      "metadata": {},
      "outputs": [],
      "source": [
        "train('swinv2_large_window12_192_22k', 192, epochs=1, accum=2, finetune=False)\n",
        "report_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d67ad28f",
      "metadata": {},
      "outputs": [],
      "source": [
        "train('swin_large_patch4_window7_224', 224, epochs=1, accum=2, finetune=False)\n",
        "report_gpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a257075e",
      "metadata": {},
      "source": [
        "## Running the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db12011a",
      "metadata": {},
      "outputs": [],
      "source": [
        "res = 640,480"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fef3143",
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    'convnext_large_in22k': {\n",
        "        (Resize(res), 224),\n",
        "        (Resize(res), (320,224)),\n",
        "    }, 'vit_large_patch16_224': {\n",
        "        (Resize(480, method='squish'), 224),\n",
        "        (Resize(res), 224),\n",
        "    }, 'swinv2_large_window12_192_22k': {\n",
        "        (Resize(480, method='squish'), 192),\n",
        "        (Resize(res), 192),\n",
        "    }, 'swin_large_patch4_window7_224': {\n",
        "        (Resize(480, method='squish'), 224),\n",
        "        (Resize(res), 224),\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc937556",
      "metadata": {},
      "outputs": [],
      "source": [
        "trn_path = path/'train_images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7248b3c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "tta_res = []\n",
        "\n",
        "for arch,details in models.items():\n",
        "    for item,size in details:\n",
        "        print('---',arch)\n",
        "        print(size)\n",
        "        print(item.name)\n",
        "        tta_res.append(train(arch, size, item=item, accum=2)) #, epochs=1))\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a86bf6a",
      "metadata": {},
      "source": [
        "## Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d27e2de1",
      "metadata": {},
      "outputs": [],
      "source": [
        "save_pickle('tta_res.pkl', tta_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8652acd4",
      "metadata": {},
      "outputs": [],
      "source": [
        "tta_prs = first(zip(*tta_res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b204b291",
      "metadata": {},
      "outputs": [],
      "source": [
        "tta_prs += tta_prs[2:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd74a6b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_pr = torch.stack(tta_prs).mean(0)\n",
        "avg_pr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b947d66b",
      "metadata": {},
      "outputs": [],
      "source": [
        "dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, item_tfms=Resize(480, method='squish'),\n",
        "    batch_tfms=aug_transforms(size=224, min_scale=0.75))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f95898b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "idxs = avg_pr.argmax(dim=1)\n",
        "vocab = np.array(dls.vocab)\n",
        "ss = pd.read_csv(path/'sample_submission.csv')\n",
        "ss['label'] = vocab[idxs]\n",
        "ss.to_csv('subm.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a9084dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not iskaggle:\n",
        "    from kaggle import api\n",
        "    api.competition_submit_cli('subm.csv', 'part 3 v2', comp)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fast-ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
