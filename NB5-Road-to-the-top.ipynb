{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminojagh/fast-ai/blob/main/NB5-Road-to-the-top.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Setup"
      ],
      "metadata": {
        "id": "2c6bBVKEKVtR"
      },
      "id": "2c6bBVKEKVtR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "using fastkaggle to setup the competition (requires ~/kaggle/kaggle.json)"
      ],
      "metadata": {
        "id": "dXBgRr4KEXw4"
      },
      "id": "dXBgRr4KEXw4"
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_config_path = '/root/.config/kaggle'\n",
        "!mkdir {kaggle_config_path}\n",
        "from google.colab import files\n",
        "files.upload(kaggle_config_path)\n",
        "!chmod 600 /root/.config/kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "RcE_XjULHmF9"
      },
      "id": "RcE_XjULHmF9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq fastkaggle fastai"
      ],
      "metadata": {
        "id": "cbwxp1jhHyVO"
      },
      "id": "cbwxp1jhHyVO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastkaggle import setup_comp, iskaggle, push_notebook\n",
        "from fastai.vision.all import (get_image_files, PILImage, set_seed,\n",
        "                               ImageDataLoaders, Resize, aug_transforms,\n",
        "                               vision_learner, error_rate, valley, slide)\n",
        "\n",
        "from fastcore.parallel import parallel\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zpPVdJX7TAqX"
      },
      "id": "zpPVdJX7TAqX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp = 'paddy-disease-classification'\n",
        "path = setup_comp(comp, install='fastai \"timm>=0.6.2.dev0\"')\n",
        "print(path)\n",
        "display(path.ls())"
      ],
      "metadata": {
        "id": "Fg4fLfOqD1AI"
      },
      "id": "Fg4fLfOqD1AI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Looaking at the Data"
      ],
      "metadata": {
        "id": "MgE3YcajKeVB"
      },
      "id": "MgE3YcajKeVB"
    },
    {
      "cell_type": "code",
      "source": [
        "trn_path = path/'train_images'\n",
        "files = get_image_files(trn_path)\n",
        "# img = PILImage.create(files[0])\n",
        "# print(img.size)\n",
        "# img.to_thumb(128)"
      ],
      "metadata": {
        "id": "sl7iFTEFKySt"
      },
      "id": "sl7iFTEFKySt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(o): return PILImage.create(o).size\n",
        "sizes = parallel(f, files, n_workers=8)\n",
        "pd.Series(sizes).value_counts()"
      ],
      "metadata": {
        "id": "FTwSoXQSLEW7"
      },
      "id": "FTwSoXQSLEW7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, seed=42,\n",
        "    item_tfms=Resize(480, method='squish'),\n",
        "    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n",
        "\n",
        "# dls.show_batch(max_n=6)"
      ],
      "metadata": {
        "id": "C549CBXIHq2s"
      },
      "id": "C549CBXIHq2s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our first model"
      ],
      "metadata": {
        "id": "Zhv4B_16IQfe"
      },
      "id": "Zhv4B_16IQfe"
    },
    {
      "cell_type": "code",
      "source": [
        "learn = vision_learner(dls, 'resnet26d', metrics=error_rate, path='.').to_fp16()\n",
        "learn.lr_find(suggest_funcs=(valley, slide))"
      ],
      "metadata": {
        "id": "URFmFdWxIB7p"
      },
      "id": "URFmFdWxIB7p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fine_tune(3, 0.01)"
      ],
      "metadata": {
        "id": "6rpsquXeIWdo"
      },
      "id": "6rpsquXeIWdo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submitting to Kaggle-I"
      ],
      "metadata": {
        "id": "jq_NojrkJauM"
      },
      "id": "jq_NojrkJauM"
    },
    {
      "cell_type": "code",
      "source": [
        "ss = pd.read_csv(path/'sample_submission.csv')\n",
        "tst_files = get_image_files(path/'test_images').sorted()\n",
        "tst_dl = dls.test_dl(tst_files)\n",
        "\n",
        "probs,_,idxs = learn.get_preds(dl=tst_dl, with_decoded=True)\n",
        "# print(idxs)\n",
        "# print(dls.vocab)\n",
        "mapping = dict(enumerate(dls.vocab))\n",
        "results = pd.Series(idxs.numpy(), name=\"idxs\").map(mapping)\n",
        "\n",
        "ss['label'] = results\n",
        "ss.to_csv('subm.csv', index=False)\n",
        "# !head subm.csv\n",
        "\n",
        "if not iskaggle:\n",
        "    from kaggle import api\n",
        "    api.competition_submit_cli('subm.csv', 'initial rn26d 128px', comp)\n",
        "    # push_notebook('jhoward', 'first-steps-road-to-the-top-part-1',\n",
        "    #               title='First Steps: Road to the Top, Part 1',\n",
        "    #               file='first-steps-road-to-the-top-part-1.ipynb',\n",
        "    #               competition=comp, private=False, gpu=True)"
      ],
      "metadata": {
        "id": "qcjwbiD7KrzQ"
      },
      "id": "qcjwbiD7KrzQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Going faster"
      ],
      "metadata": {
        "id": "KybsWmeSU8Bz"
      },
      "id": "KybsWmeSU8Bz"
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from fastai.vision.all import resize_images, ResizeMethod, PadMode\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "45VKhRw9U8iF"
      },
      "id": "45VKhRw9U8iF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn_path = Path('sml')\n",
        "resize_images(path/'train_images', dest=trn_path, max_size=256, recurse=True)"
      ],
      "metadata": {
        "id": "-MTE4CxqYwKX"
      },
      "id": "-MTE4CxqYwKX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(trn_path, arch, item, batch, epochs=5):\n",
        "    dls = ImageDataLoaders.from_folder(trn_path, seed=42, valid_pct=0.2, item_tfms=item, batch_tfms=batch)\n",
        "    learn = vision_learner(dls, arch, metrics=error_rate).to_fp16()\n",
        "    learn.fine_tune(epochs, 0.01)\n",
        "    return learn"
      ],
      "metadata": {
        "id": "Ka7mk_MuVdRa"
      },
      "id": "Ka7mk_MuVdRa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # our initial model\n",
        "# learn = train(trn_path,\n",
        "#               'resnet26d',\n",
        "#               item=Resize(192),\n",
        "#               batch=aug_transforms(size=128, min_scale=0.75))"
      ],
      "metadata": {
        "id": "-qc63M_gcNtP"
      },
      "id": "-qc63M_gcNtP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A ConvNeXt model"
      ],
      "metadata": {
        "id": "A-731ARwWm7L"
      },
      "id": "A-731ARwWm7L"
    },
    {
      "cell_type": "code",
      "source": [
        "arch = 'convnext_small_in22k'\n",
        "\n",
        "# learn = train(trn_path,\n",
        "#               arch,\n",
        "#               item=Resize(192, method='squish'), # the default method is 'crop'\n",
        "#               batch=aug_transforms(size=128, min_scale=0.75))\n",
        "\n",
        "learn = train(trn_path,\n",
        "              arch,\n",
        "              item=Resize((256,192),\n",
        "                          method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n",
        "              batch=aug_transforms(size=(171,128), min_scale=0.75))"
      ],
      "metadata": {
        "id": "2iBX79kVWnpB"
      },
      "id": "2iBX79kVWnpB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test time augmentation"
      ],
      "metadata": {
        "id": "lot2dUyqW4cc"
      },
      "id": "lot2dUyqW4cc"
    },
    {
      "cell_type": "code",
      "source": [
        "valid = learn.dls.valid\n",
        "preds,targs = learn.get_preds(dl=valid)\n",
        "error_rate(preds, targs)"
      ],
      "metadata": {
        "id": "5QgEZ_PnW5LH"
      },
      "id": "5QgEZ_PnW5LH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tta_preds,_ = learn.tta(dl=valid)\n",
        "error_rate(tta_preds, targs)"
      ],
      "metadata": {
        "id": "fJs5sk-OcA76"
      },
      "id": "fJs5sk-OcA76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling up"
      ],
      "metadata": {
        "id": "vGCG_Bb8XAHA"
      },
      "id": "vGCG_Bb8XAHA"
    },
    {
      "cell_type": "code",
      "source": [
        "trn_path = path/'train_images'\n",
        "\n",
        "learn = train(trn_path,\n",
        "              arch,\n",
        "              epochs=12,\n",
        "              item=Resize((480, 360), method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n",
        "              batch=aug_transforms(size=(256,192), min_scale=0.75))\n",
        "\n",
        "tta_preds,targs = learn.tta(dl=learn.dls.valid)\n",
        "error_rate(tta_preds, targs)"
      ],
      "metadata": {
        "id": "YMM93b06XAmQ"
      },
      "id": "YMM93b06XAmQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submitting to Kaggle-II"
      ],
      "metadata": {
        "id": "rs8n3_fOXJnR"
      },
      "id": "rs8n3_fOXJnR"
    },
    {
      "cell_type": "code",
      "source": [
        "def submit_to_kaggle(sample_sub_file_path:Path,\n",
        "                     test_images_path:Path,\n",
        "                     is_kaggle:bool, tta:bool,\n",
        "                     sub_title:str\n",
        "                     ):\n",
        "\n",
        "  ss = pd.read_csv(sample_sub_file_path)\n",
        "  tst_files = get_image_files(test_images_path).sorted()\n",
        "  tst_dl = learn.dls.test_dl(tst_files)\n",
        "\n",
        "  if tta:\n",
        "    preds,_ = learn.tta(dl=tst_dl)\n",
        "    idxs = preds.argmax(dim=1)\n",
        "  else:\n",
        "    probs,_,idxs = learn.get_preds(dl=tst_dl, with_decoded=True)\n",
        "\n",
        "  vocab = np.array(learn.dls.vocab)\n",
        "  results = pd.Series(vocab[idxs], name=\"idxs\")\n",
        "\n",
        "\n",
        "  ss['label'] = results\n",
        "  ss.to_csv('subm.csv', index=False)\n",
        "\n",
        "  if not iskaggle:\n",
        "      from kaggle import api\n",
        "      api.competition_submit_cli('subm.csv', sub_title, comp)"
      ],
      "metadata": {
        "id": "Maju8a3vjb68"
      },
      "id": "Maju8a3vjb68",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit_to_kaggle(sample_sub_file_path = path/'sample_submission.csv',\n",
        "                 test_images_path = path/'test_images',\n",
        "                 is_kaggle = iskaggle, tta = True,\n",
        "                 sub_title = 'convnext small 256x192 12 epochs tta')"
      ],
      "metadata": {
        "id": "-24-ITauXK8E"
      },
      "id": "-24-ITauXK8E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S-NCG1JJqBX7"
      },
      "id": "S-NCG1JJqBX7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}