{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminojagh/fast-ai/blob/main/NB5-Road-to-the-top.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c6bBVKEKVtR",
      "metadata": {
        "id": "2c6bBVKEKVtR"
      },
      "source": [
        "## Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dXBgRr4KEXw4",
      "metadata": {
        "id": "dXBgRr4KEXw4"
      },
      "source": [
        "using fastkaggle to setup the competition (requires ~/kaggle/kaggle.json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RcE_XjULHmF9",
      "metadata": {
        "id": "RcE_XjULHmF9"
      },
      "outputs": [],
      "source": [
        "kaggle_config_path = '/root/.config/kaggle'\n",
        "!mkdir {kaggle_config_path}\n",
        "from google.colab import files\n",
        "files.upload(kaggle_config_path)\n",
        "!chmod 600 /root/.config/kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbwxp1jhHyVO",
      "metadata": {
        "id": "cbwxp1jhHyVO"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq fastkaggle fastai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zpPVdJX7TAqX",
      "metadata": {
        "id": "zpPVdJX7TAqX"
      },
      "outputs": [],
      "source": [
        "from fastkaggle import setup_comp, iskaggle, push_notebook\n",
        "from fastai.vision.all import (get_image_files, PILImage, set_seed,\n",
        "                               ImageDataLoaders, Resize, aug_transforms,\n",
        "                               vision_learner, error_rate, valley, slide,\n",
        "                               GradientAccumulation, save_pickle, first)\n",
        "\n",
        "from fastcore.parallel import parallel\n",
        "import pandas as pd, numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fg4fLfOqD1AI",
      "metadata": {
        "id": "Fg4fLfOqD1AI"
      },
      "outputs": [],
      "source": [
        "comp = 'paddy-disease-classification'\n",
        "# path = setup_comp(comp, install='fastai \"timm>=0.6.2.dev0\"')\n",
        "path = setup_comp(comp, install='fastai timm')\n",
        "print(path)\n",
        "display(path.ls())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MgE3YcajKeVB",
      "metadata": {
        "id": "MgE3YcajKeVB"
      },
      "source": [
        "## Looaking at the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sl7iFTEFKySt",
      "metadata": {
        "id": "sl7iFTEFKySt"
      },
      "outputs": [],
      "source": [
        "trn_path = path/'train_images'\n",
        "files = get_image_files(trn_path)\n",
        "# img = PILImage.create(files[0])\n",
        "# print(img.size)\n",
        "# img.to_thumb(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FTwSoXQSLEW7",
      "metadata": {
        "id": "FTwSoXQSLEW7"
      },
      "outputs": [],
      "source": [
        "def f(o): return PILImage.create(o).size\n",
        "sizes = parallel(f, files, n_workers=8)\n",
        "pd.Series(sizes).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C549CBXIHq2s",
      "metadata": {
        "id": "C549CBXIHq2s"
      },
      "outputs": [],
      "source": [
        "dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, seed=42,\n",
        "    item_tfms=Resize(480, method='squish'),\n",
        "    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n",
        "\n",
        "# dls.show_batch(max_n=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Zhv4B_16IQfe",
      "metadata": {
        "id": "Zhv4B_16IQfe"
      },
      "source": [
        "## Our first model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "URFmFdWxIB7p",
      "metadata": {
        "id": "URFmFdWxIB7p"
      },
      "outputs": [],
      "source": [
        "learn = vision_learner(dls, 'resnet26d', metrics=error_rate, path='.').to_fp16()\n",
        "learn.lr_find(suggest_funcs=(valley, slide))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6rpsquXeIWdo",
      "metadata": {
        "id": "6rpsquXeIWdo"
      },
      "outputs": [],
      "source": [
        "learn.fine_tune(3, 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jq_NojrkJauM",
      "metadata": {
        "id": "jq_NojrkJauM"
      },
      "source": [
        "## Submitting to Kaggle-I"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qcjwbiD7KrzQ",
      "metadata": {
        "id": "qcjwbiD7KrzQ"
      },
      "outputs": [],
      "source": [
        "ss = pd.read_csv(path/'sample_submission.csv')\n",
        "tst_files = get_image_files(path/'test_images').sorted()\n",
        "tst_dl = dls.test_dl(tst_files)\n",
        "\n",
        "probs,_,idxs = learn.get_preds(dl=tst_dl, with_decoded=True)\n",
        "# print(idxs)\n",
        "# print(dls.vocab)\n",
        "mapping = dict(enumerate(dls.vocab))\n",
        "results = pd.Series(idxs.numpy(), name=\"idxs\").map(mapping)\n",
        "\n",
        "ss['label'] = results\n",
        "ss.to_csv('subm.csv', index=False)\n",
        "# !head subm.csv\n",
        "\n",
        "if not iskaggle:\n",
        "    from kaggle import api\n",
        "    api.competition_submit_cli('subm.csv', 'initial rn26d 128px', comp)\n",
        "    # push_notebook('jhoward', 'first-steps-road-to-the-top-part-1',\n",
        "    #               title='First Steps: Road to the Top, Part 1',\n",
        "    #               file='first-steps-road-to-the-top-part-1.ipynb',\n",
        "    #               competition=comp, private=False, gpu=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KybsWmeSU8Bz",
      "metadata": {
        "id": "KybsWmeSU8Bz"
      },
      "source": [
        "## Going faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45VKhRw9U8iF",
      "metadata": {
        "id": "45VKhRw9U8iF"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from fastai.vision.all import resize_images, ResizeMethod, PadMode\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-MTE4CxqYwKX",
      "metadata": {
        "id": "-MTE4CxqYwKX"
      },
      "outputs": [],
      "source": [
        "trn_path = Path('sml')\n",
        "resize_images(path/'train_images', dest=trn_path, max_size=256, recurse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ka7mk_MuVdRa",
      "metadata": {
        "id": "Ka7mk_MuVdRa"
      },
      "outputs": [],
      "source": [
        "def train(trn_path, arch, item, batch, epochs=5):\n",
        "    dls = ImageDataLoaders.from_folder(trn_path, seed=42, valid_pct=0.2, item_tfms=item, batch_tfms=batch)\n",
        "    learn = vision_learner(dls, arch, metrics=error_rate).to_fp16()\n",
        "    learn.fine_tune(epochs, 0.01)\n",
        "    return learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-qc63M_gcNtP",
      "metadata": {
        "id": "-qc63M_gcNtP"
      },
      "outputs": [],
      "source": [
        "# # our initial model\n",
        "# learn = train(trn_path,\n",
        "#               'resnet26d',\n",
        "#               item=Resize(192),\n",
        "#               batch=aug_transforms(size=128, min_scale=0.75))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A-731ARwWm7L",
      "metadata": {
        "id": "A-731ARwWm7L"
      },
      "source": [
        "## A ConvNeXt model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2iBX79kVWnpB",
      "metadata": {
        "id": "2iBX79kVWnpB"
      },
      "outputs": [],
      "source": [
        "arch = 'convnext_small_in22k'\n",
        "\n",
        "# learn = train(trn_path,\n",
        "#               arch,\n",
        "#               item=Resize(192, method='squish'), # the default method is 'crop'\n",
        "#               batch=aug_transforms(size=128, min_scale=0.75))\n",
        "\n",
        "learn = train(trn_path,\n",
        "              arch,\n",
        "              item=Resize((256,192),\n",
        "                          method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n",
        "              batch=aug_transforms(size=(171,128), min_scale=0.75))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lot2dUyqW4cc",
      "metadata": {
        "id": "lot2dUyqW4cc"
      },
      "source": [
        "## Test time augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5QgEZ_PnW5LH",
      "metadata": {
        "id": "5QgEZ_PnW5LH"
      },
      "outputs": [],
      "source": [
        "valid = learn.dls.valid\n",
        "preds,targs = learn.get_preds(dl=valid)\n",
        "error_rate(preds, targs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fJs5sk-OcA76",
      "metadata": {
        "id": "fJs5sk-OcA76"
      },
      "outputs": [],
      "source": [
        "tta_preds,_ = learn.tta(dl=valid)\n",
        "error_rate(tta_preds, targs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vGCG_Bb8XAHA",
      "metadata": {
        "id": "vGCG_Bb8XAHA"
      },
      "source": [
        "## Scaling up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YMM93b06XAmQ",
      "metadata": {
        "id": "YMM93b06XAmQ"
      },
      "outputs": [],
      "source": [
        "trn_path = path/'train_images'\n",
        "\n",
        "learn = train(trn_path,\n",
        "              arch,\n",
        "              epochs=12,\n",
        "              item=Resize((480, 360), method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n",
        "              batch=aug_transforms(size=(256,192), min_scale=0.75))\n",
        "\n",
        "tta_preds,targs = learn.tta(dl=learn.dls.valid)\n",
        "error_rate(tta_preds, targs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rs8n3_fOXJnR",
      "metadata": {
        "id": "rs8n3_fOXJnR"
      },
      "source": [
        "## Submitting to Kaggle-II"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Maju8a3vjb68",
      "metadata": {
        "id": "Maju8a3vjb68"
      },
      "outputs": [],
      "source": [
        "def submit_to_kaggle(sample_sub_file_path:Path,\n",
        "                     test_images_path:Path,\n",
        "                     iskaggle:bool, tta:bool,\n",
        "                     sub_title:str\n",
        "                     ):\n",
        "\n",
        "  ss = pd.read_csv(sample_sub_file_path)\n",
        "  tst_files = get_image_files(test_images_path).sorted()\n",
        "  tst_dl = learn.dls.test_dl(tst_files)\n",
        "\n",
        "  if tta:\n",
        "    preds,_ = learn.tta(dl=tst_dl)\n",
        "    idxs = preds.argmax(dim=1)\n",
        "  else:\n",
        "    probs,_,idxs = learn.get_preds(dl=tst_dl, with_decoded=True)\n",
        "\n",
        "  vocab = np.array(learn.dls.vocab)\n",
        "  results = pd.Series(vocab[idxs], name=\"idxs\")\n",
        "\n",
        "\n",
        "  ss['label'] = results\n",
        "  ss.to_csv('subm.csv', index=False)\n",
        "\n",
        "  if not iskaggle:\n",
        "      from kaggle import api\n",
        "      api.competition_submit_cli('subm.csv', sub_title, comp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-24-ITauXK8E",
      "metadata": {
        "id": "-24-ITauXK8E"
      },
      "outputs": [],
      "source": [
        "submit_to_kaggle(sample_sub_file_path = path/'sample_submission.csv',\n",
        "                 test_images_path = path/'test_images',\n",
        "                 iskaggle = iskaggle, tta = True,\n",
        "                 sub_title = 'convnext small 256x192 12 epochs tta')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76e3c867",
      "metadata": {
        "id": "76e3c867"
      },
      "source": [
        "## Memory and gradient accumulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S-NCG1JJqBX7",
      "metadata": {
        "id": "S-NCG1JJqBX7"
      },
      "outputs": [],
      "source": [
        "tst_files = get_image_files(path/'test_images').sorted()\n",
        "df = pd.read_csv(path/'train.csv')\n",
        "df.label.value_counts()\n",
        "trn_path = path/'train_images'/'bacterial_panicle_blight'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae4cefea",
      "metadata": {
        "id": "ae4cefea"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    arch, size, item=Resize(480, method='squish'),\n",
        "    accum=1, finetune=True, epochs=12\n",
        "):\n",
        "    dls = ImageDataLoaders.from_folder(\n",
        "        trn_path, valid_pct=0.2, item_tfms=item,\n",
        "        batch_tfms=aug_transforms(size=size, min_scale=0.75),\n",
        "        bs=64//accum\n",
        "    )\n",
        "    cbs = GradientAccumulation(64) if accum else []\n",
        "    learn = vision_learner(\n",
        "        dls, arch, metrics=error_rate, cbs=cbs\n",
        "    ).to_fp16()\n",
        "    if finetune:\n",
        "        learn.fine_tune(epochs, 0.01)\n",
        "        return learn.tta(dl=dls.test_dl(tst_files))\n",
        "    else:\n",
        "        learn.unfreeze()\n",
        "        learn.fit_one_cycle(epochs, 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6cd2941",
      "metadata": {
        "id": "b6cd2941"
      },
      "source": [
        "## Checking memory use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b8ddf7e",
      "metadata": {
        "id": "9b8ddf7e"
      },
      "outputs": [],
      "source": [
        "import gc, torch\n",
        "def report_gpu():\n",
        "    print(torch.cuda.list_gpu_processes())\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7d07972",
      "metadata": {
        "id": "c7d07972"
      },
      "outputs": [],
      "source": [
        "train('convnext_small_in22k', 128, epochs=1, accum=1, finetune=False)\n",
        "report_gpu()\n",
        "\n",
        "train('convnext_small_in22k', 128, epochs=1, accum=2, finetune=False)\n",
        "report_gpu()\n",
        "\n",
        "train('convnext_small_in22k', 128, epochs=1, accum=4, finetune=False)\n",
        "report_gpu()\n",
        "\n",
        "train('convnext_large_in22k', 224, epochs=1, accum=2, finetune=False)\n",
        "report_gpu()\n",
        "\n",
        "train('convnext_large_in22k', (320,240), epochs=1,\n",
        "      accum=2, finetune=False)\n",
        "report_gpu()\n",
        "\n",
        "train('vit_large_patch16_224', 224, epochs=1, accum=2, finetune=False)\n",
        "report_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73448fc7",
      "metadata": {
        "id": "73448fc7"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.empty_cache()\n",
        "# train('swinv2_large_window12_192_22k', 192, epochs=1,\n",
        "#       accum=4, finetune=False)\n",
        "# report_gpu()\n",
        "\n",
        "# --------------------\n",
        "\n",
        "# train('swin_large_patch4_window7_224', 224, epochs=1, accum=4, finetune=False)\n",
        "# report_gpu()\n",
        "\n",
        "# Results in an Error related to timm version"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a257075e",
      "metadata": {
        "id": "a257075e"
      },
      "source": [
        "## Running the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7248b3c3",
      "metadata": {
        "collapsed": true,
        "id": "7248b3c3"
      },
      "outputs": [],
      "source": [
        "res = 640,480\n",
        "\n",
        "models = {\n",
        "    # 'convnext_large_in22k': {\n",
        "    #     (Resize(res), 224),\n",
        "    #     # (Resize(res), (320,224)),\n",
        "    # },\n",
        "    'vit_large_patch16_224': {\n",
        "        (Resize(480, method='squish'), 224),\n",
        "        # (Resize(res), 224),\n",
        "    },\n",
        "    # 'swinv2_large_window12_192_22k': {\n",
        "    #     (Resize(480, method='squish'), 192),\n",
        "    #     (Resize(res), 192),\n",
        "    # },\n",
        "    # 'swin_large_patch4_window7_224': {\n",
        "    #     (Resize(480, method='squish'), 224),\n",
        "    #     (Resize(res), 224),\n",
        "    # }\n",
        "}\n",
        "\n",
        "\n",
        "trn_path = path/'train_images'\n",
        "\n",
        "tta_res = []\n",
        "\n",
        "for arch,details in models.items():\n",
        "    for item,size in details:\n",
        "        print('---',arch)\n",
        "        print(size)\n",
        "        print(item.name)\n",
        "        tta_res.append(train(arch, size, item=item, accum=4)) #, epochs=1))\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a86bf6a",
      "metadata": {
        "id": "3a86bf6a"
      },
      "source": [
        "## Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d27e2de1",
      "metadata": {
        "id": "d27e2de1"
      },
      "outputs": [],
      "source": [
        "save_pickle('tta_res.pkl', tta_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8652acd4",
      "metadata": {
        "id": "8652acd4"
      },
      "outputs": [],
      "source": [
        "tta_prs = first(zip(*tta_res))\n",
        "# tta_prs += tta_prs[2:4]\n",
        "avg_pr = torch.stack(tta_prs).mean(0)\n",
        "print(avg_pr.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f95898b4",
      "metadata": {
        "id": "f95898b4"
      },
      "outputs": [],
      "source": [
        "dls = ImageDataLoaders.from_folder(\n",
        "    trn_path, valid_pct=0.2,\n",
        "    item_tfms=Resize(480, method='squish'),\n",
        "    batch_tfms=aug_transforms(size=224, min_scale=0.75)\n",
        ")\n",
        "\n",
        "idxs = avg_pr.argmax(dim=1)\n",
        "vocab = np.array(dls.vocab)\n",
        "ss = pd.read_csv(path/'sample_submission.csv')\n",
        "ss['label'] = vocab[idxs]\n",
        "ss.to_csv('subm.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rPUPVEKZTkn0",
      "metadata": {
        "id": "rPUPVEKZTkn0"
      },
      "source": [
        "## Submitting to Kaggle-III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a9084dd",
      "metadata": {
        "id": "1a9084dd"
      },
      "outputs": [],
      "source": [
        "if not iskaggle:\n",
        "    from kaggle import api\n",
        "    api.competition_submit_cli('subm.csv', 'convnext_vit_ensemble', comp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfb9b3b1",
      "metadata": {
        "id": "cfb9b3b1"
      },
      "source": [
        "## Part4 | Multi-output Predicion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a704865",
      "metadata": {
        "id": "6a704865"
      },
      "source": [
        "In this part we're going to build a model that doesn't just predict what disease the rice paddy has, but also predicts what kind of rice is shown.\n",
        "\n",
        "This might sound like a bad idea. After all, doesn't that mean that the model has *more* to do? Mightn't it get rather distracted from its main task, which is to identify paddy disease?\n",
        "\n",
        "Perhaps... But in previous projects I've often found the opposite to be true, especially when training for quite a few epochs. By giving the model more signal about what is present in a picture, it may be able to use this information to find more interesting features that predict our target of interest. For instance, perhaps some of the features of disease change between varieties."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c491455e",
      "metadata": {
        "id": "c491455e"
      },
      "source": [
        "## Multi-output `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7569690",
      "metadata": {
        "id": "d7569690"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import (\n",
        "    DataBlock, ImageBlock, CategoryBlock,\n",
        "    parent_label, RandomSplitter, set_seed, F\n",
        ")\n",
        "# from fastcore.parallel import *\n",
        "set_seed(42)\n",
        "trn_path = path/'train_images'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c65208a9",
      "metadata": {
        "id": "c65208a9"
      },
      "source": [
        "First we'll repeat the steps we used last time to access the data and ensure all the latest libraries are installed:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37e30a7d",
      "metadata": {
        "id": "37e30a7d"
      },
      "source": [
        "Here's the CSV that Kaggle provides, showing the variety of rice contained in each image -- we'll make `image_id` the index of our data frame so that we can look up images directly to grab their variety:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3df04d83",
      "metadata": {
        "id": "3df04d83"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path/'train.csv', index_col='image_id')\n",
        "display(df.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_variety(p): return df.loc[p.name, 'variety']"
      ],
      "metadata": {
        "id": "yVG0J6YlniAO"
      },
      "id": "yVG0J6YlniAO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how to get labels\n",
        "image_list = get_image_files(trn_path)\n",
        "print(f\"disease: {parent_label(image_list[0])} | variety:\\\n",
        " {get_variety(image_list[0])}\")"
      ],
      "metadata": {
        "id": "Nuk_TD0ak6KV"
      },
      "id": "Nuk_TD0ak6KV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b93e755",
      "metadata": {
        "id": "6b93e755"
      },
      "outputs": [],
      "source": [
        "dls = DataBlock(\n",
        "    blocks=(ImageBlock,CategoryBlock,CategoryBlock),\n",
        "    n_inp=1,\n",
        "    get_items=get_image_files,\n",
        "    get_y = [parent_label,get_variety],\n",
        "    splitter=RandomSplitter(0.2, seed=42),\n",
        "    item_tfms=Resize(192, method='squish'),\n",
        "    batch_tfms=aug_transforms(size=128, min_scale=0.75)\n",
        ").dataloaders(trn_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "533c7d05",
      "metadata": {
        "id": "533c7d05"
      },
      "source": [
        "Here's an explanation of each line:\n",
        "\n",
        "```python\n",
        "blocks=(ImageBlock,CategoryBlock,CategoryBlock),\n",
        "```\n",
        "\n",
        "The `DataBlock` will create 3 things from each file: an image (the contents of the file), and 2 categorical variables (the disease and the variety).\n",
        "\n",
        "```python\n",
        "n_inp=1,\n",
        "```\n",
        "\n",
        "There is `1` input (the image) -- and therefore the other two variables (the two categories) are outputs.\n",
        "\n",
        "```python\n",
        "get_items=get_image_files,\n",
        "```\n",
        "\n",
        "Use `get_image_files` to get a list of inputs.\n",
        "\n",
        "```python\n",
        "get_y = [parent_label,get_variety],\n",
        "```\n",
        "\n",
        "To create the two outputs for each file, call two functions: `parent_label` (from fastai) and `get_variety` (defined above).\n",
        "\n",
        "```python\n",
        "splitter=RandomSplitter(0.2, seed=42),\n",
        "```\n",
        "\n",
        "Randomly split the input into 80% train and 20% validation sets.\n",
        "\n",
        "```python\n",
        "item_tfms=Resize(192, method='squish'),\n",
        "batch_tfms=aug_transforms(size=128, min_scale=0.75)\n",
        "```\n",
        "\n",
        "These are the same item and batch transforms we've used in previous notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15ed65f8",
      "metadata": {
        "id": "15ed65f8"
      },
      "source": [
        "Let's take a look at part of a batch of this data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1e0a66b",
      "metadata": {
        "id": "a1e0a66b"
      },
      "outputs": [],
      "source": [
        "dls.show_batch(max_n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de89a91",
      "metadata": {
        "id": "3de89a91"
      },
      "source": [
        "We can see that fastai has created both the image input and two categorical outputs that we requested!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "900dcd31",
      "metadata": {
        "id": "900dcd31"
      },
      "source": [
        "## Replicating the disease model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3ddc224",
      "metadata": {
        "id": "b3ddc224"
      },
      "source": [
        "Now we'll replicate the same disease model we've made before, but have it work with this new data.\n",
        "\n",
        "The key difference is that our metrics and loss will now receive three things instead of two: the model outputs (i.e. the metric and loss function inputs), and the two targets (disease and variety). Therefore, we need to define slight variations of our metric (`error_rate`) and loss function (`cross_entropy`) to pass on just the `disease` target:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b0e62c",
      "metadata": {
        "id": "51b0e62c"
      },
      "outputs": [],
      "source": [
        "# def disease_err(inp,disease,variety): return error_rate(inp,disease)\n",
        "# def disease_loss(inp,disease,variety): return F.cross_entropy(inp,disease)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f76112",
      "metadata": {
        "id": "69f76112"
      },
      "source": [
        "We're now ready to create our learner.\n",
        "\n",
        "There's just one wrinkle to be aware of. Now that our `DataLoaders` is returning multiple targets, fastai doesn't know how many outputs our model will need. Therefore we have to pass `n_out` when we create our `Learner` -- we need `10` outputs, one for each possible disease:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0db67a4",
      "metadata": {
        "id": "e0db67a4"
      },
      "outputs": [],
      "source": [
        "# arch = 'convnext_small_in22k'\n",
        "# learn = vision_learner(dls, arch, loss_func=disease_loss,\n",
        "#                        metrics=disease_err, n_out=10).to_fp16()\n",
        "# lr = 0.01\n",
        "\n",
        "# # When we train this model we should get similar results\n",
        "# # to what we've seen with similar models before:\n",
        "# learn.fine_tune(5, lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da77bbf",
      "metadata": {
        "id": "6da77bbf"
      },
      "source": [
        "## Multi-target model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26fcf380",
      "metadata": {
        "id": "26fcf380"
      },
      "source": [
        "In order to predict both the probability of each disease, and of each variety, we'll now need the model to output a tensor of length 20, since there are 10 possible diseases, and 10 possible varieties. We can do this by setting `n_out=20`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80726daf",
      "metadata": {
        "id": "80726daf"
      },
      "source": [
        "We can define `disease_loss` just like we did previously, but with one important change: the input tensor is now length 20, not 10, so it doesn't match the number of possible diseases. We can pick whatever part of the input we want to be used to predict disease. Let's use the first 10 values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "143aabe4",
      "metadata": {
        "id": "143aabe4"
      },
      "outputs": [],
      "source": [
        "# the first second 10 items for the disease loss\n",
        "def disease_loss(inp,disease,variety):\n",
        "  return F.cross_entropy(inp[:,:10],disease)\n",
        "# and the second 10 items for the variety loss\n",
        "def variety_loss(inp,disease,variety):\n",
        "  return F.cross_entropy(inp[:,10:],variety)\n",
        "\n",
        "# overall loss function\n",
        "def combine_loss(inp,disease,variety):\n",
        "  return (disease_loss(inp,disease,variety)+\n",
        "          variety_loss(inp,disease,variety))\n",
        "\n",
        "def disease_err(inp,disease,variety):\n",
        "  return error_rate(inp[:,:10],disease)\n",
        "def variety_err(inp,disease,variety):\n",
        "  return error_rate(inp[:,10:],variety)\n",
        "\n",
        "err_metrics = (disease_err,variety_err)\n",
        "all_metrics = err_metrics+(disease_loss,variety_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79e72dac",
      "metadata": {
        "id": "79e72dac"
      },
      "source": [
        "We're now ready to create and train our `Learner`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1de8f61c",
      "metadata": {
        "id": "1de8f61c"
      },
      "outputs": [],
      "source": [
        "arch = 'convnext_small_in22k'\n",
        "learn = vision_learner(dls, arch, loss_func=combine_loss,\n",
        "                       metrics=all_metrics, n_out=20).to_fp16()\n",
        "learn.fine_tune(10, base_lr = 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b40a35",
      "metadata": {
        "id": "56b40a35"
      },
      "source": [
        "## Submitting to Kaggle-IV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_path = path/'test_images'\n",
        "tst_files = get_image_files(test_images_path).sorted()\n",
        "tst_dl = learn.dls.test_dl(tst_files)\n",
        "\n",
        "# tta\n",
        "preds,_ = learn.tta(dl=tst_dl)"
      ],
      "metadata": {
        "id": "pVPNKifytWlL"
      },
      "id": "pVPNKifytWlL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idxs = preds[:, :10].argmax(dim=1)\n",
        "vocab = np.array(learn.dls.vocab)[0]\n",
        "results = pd.Series(vocab[idxs], name=\"idxs\")"
      ],
      "metadata": {
        "id": "K16uuOVc2Sjt"
      },
      "id": "K16uuOVc2Sjt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sub_file_path = path/'sample_submission.csv'\n",
        "ss = pd.read_csv(sample_sub_file_path)\n",
        "ss['label'] = results\n",
        "ss.to_csv('subm.csv', index=False)\n",
        "\n",
        "sub_title = 'Multi-output ConvNext | Disease and Variety'\n",
        "from kaggle import api\n",
        "api.competition_submit_cli('subm.csv', sub_title, comp)"
      ],
      "metadata": {
        "id": "0iI8CzgC1OZG"
      },
      "id": "0iI8CzgC1OZG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75680ec0"
      },
      "source": [
        "## Conclusion"
      ],
      "id": "75680ec0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeb37a5b"
      },
      "source": [
        "So, is this useful?\n",
        "\n",
        "Well... if you actually want a model that predicts multiple things, then yes, definitely! But as to whether it's going to help us better predict rice disease, I honestly don't know. I haven't come across any research that tackles this important question: when can a multi-target model improve the accuracy of the individual targets compared to a single target model? (That doesn't mean it doesn't exist of course -- perhaps it does and I haven't found it yet...)\n",
        "\n",
        "I've certainly found in previous projects that there are cases where improvements to single targets can be made by using a multi-target model. I'd guess that it'll be most useful when you're having problems with overfitting."
      ],
      "id": "eeb37a5b"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}